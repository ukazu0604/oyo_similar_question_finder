{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Vectorization with Ollama (EmbeddingGemma)\n",
                "\n",
                "This notebook installs Ollama, pulls the `embeddinggemma` model, and vectorizes text data from an uploaded CSV file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install dependencies\n",
                "!pip install colab-xterm ollama"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Install and Start Ollama\n",
                "# This runs in the background.\n",
                "get_ipython().system_raw('curl -fsSL https://ollama.com/install.sh | sh')\n",
                "get_ipython().system_raw('ollama serve &')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Pull the model\n",
                "# Wait a few seconds for the server to start before running this.\n",
                "import time\n",
                "time.sleep(5)\n",
                "!ollama pull embeddinggemma:latest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Upload CSV file\n",
                "from google.colab import files\n",
                "import pandas as pd\n",
                "import io\n",
                "\n",
                "uploaded = files.upload()\n",
                "filename = next(iter(uploaded))\n",
                "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
                "print(f\"Loaded {len(df)} rows from {filename}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Vectorize\n",
                "import ollama\n",
                "from tqdm import tqdm\n",
                "\n",
                "tqdm.pandas()\n",
                "\n",
                "# Define the column to vectorize. Change '問題名' if necessary.\n",
                "TARGET_COLUMN = '問題名'\n",
                "\n",
                "def get_embedding(text):\n",
                "    try:\n",
                "        # Ensure text is a string\n",
                "        if not isinstance(text, str):\n",
                "            text = str(text)\n",
                "        response = ollama.embeddings(model=\"embeddinggemma:latest\", prompt=text)\n",
                "        return response[\"embedding\"]\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing '{text}': {e}\")\n",
                "        return []\n",
                "\n",
                "print(f\"Vectorizing column: {TARGET_COLUMN}...\")\n",
                "# Apply the function with a progress bar\n",
                "df['embedding'] = df[TARGET_COLUMN].progress_apply(get_embedding)\n",
                "\n",
                "print(\"Vectorization complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Save to JSON\n",
                "# Convert dataframe to list of dicts or just save the embeddings with ID\n",
                "output_filename = \"gemma_embeddings.json\"\n",
                "\n",
                "# Saving the entire dataframe as JSON\n",
                "df.to_json(output_filename, orient='records', force_ascii=False, indent=2)\n",
                "\n",
                "print(f\"Saved to {output_filename}\")\n",
                "files.download(output_filename)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}