{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 応用情報技術者試験 ベクトル化ノートブック\n",
                "\n",
                "このノートブックは Google Colab または VSCode で実行できます。\n",
                "\n",
                "## 実行手順\n",
                "\n",
                "1. **ファイルのアップロード**: `ap_siken_all_items.csv` をアップロード\n",
                "2. **モデルの選択**: 使用するモデルを設定\n",
                "3. **セルを順番に実行**: すべてのセルを実行\n",
                "4. **結果のダウンロード**: `ap_siken_all_items_vectors.csv` をダウンロード"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 必要なライブラリのインストール"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q sentence-transformers pandas numpy tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ライブラリのインポート"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import time\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from tqdm.auto import tqdm\n",
                "from google.colab import files\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 設定"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 使用するモデルを選択（コメントアウトを外して選択）\n",
                "# MODEL_NAME = \"pkshatech/GLuCoSE-base-ja\"  # 日本語特化モデル\n",
                "MODEL_NAME = \"intfloat/multilingual-e5-large\"  # 多言語対応モデル（推奨）\n",
                "# MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"  # 軽量版\n",
                "\n",
                "BATCH_SIZE = 32  # バッチサイズ（メモリに応じて調整）\n",
                "TEXT_COLUMN = \"問題名\"  # ベクトル化する列名"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. CSVファイルのアップロード\n",
                "\n",
                "**注意**: Google Colabで実行する場合、ファイルをアップロードしてください。\n",
                "VSCodeで実行する場合は、このセルをスキップして次のセルで直接ファイルパスを指定してください。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Google Colab用: ファイルをアップロード\n",
                "# uploaded = files.upload()\n",
                "# input_filename = list(uploaded.keys())[0]\n",
                "# print(f\"アップロードされたファイル: {input_filename}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VSCode用: ローカルファイルを直接指定（上のセルの代わりにこちらを使用）\n",
                "input_filename = \"../01_scraping/ap_siken_all_items.csv\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. データの読み込み"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-26 14:26:46] データを読み込んでいます...\n"
                    ]
                },
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '../01_scraping/ap_siken_all_items.csv'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-1166948407.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] データを読み込んでいます...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8-sig'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] データ読み込み完了: {len(df)}行\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nカラム: {list(df.columns)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n最初の3行:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../01_scraping/ap_siken_all_items.csv'"
                    ]
                }
            ],
            "source": [
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] データを読み込んでいます...\")\n",
                "df = pd.read_csv(input_filename, encoding='utf-8-sig')\n",
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] データ読み込み完了: {len(df)}行\")\n",
                "print(f\"\\nカラム: {list(df.columns)}\")\n",
                "print(f\"\\n最初の3行:\")\n",
                "display(df.head(3))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. テキストの抽出"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipython-input-1662343113.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mTEXT_COLUMN\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"エラー: カラム '{TEXT_COLUMN}' が見つかりません。\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEXT_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] テキスト抽出完了: {len(texts)}件\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
                    ]
                }
            ],
            "source": [
                "if TEXT_COLUMN not in df.columns:\n",
                "    raise ValueError(f\"エラー: カラム '{TEXT_COLUMN}' が見つかりません。\")\n",
                "\n",
                "texts = df[TEXT_COLUMN].fillna('').tolist()\n",
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] テキスト抽出完了: {len(texts)}件\")\n",
                "print(f\"\\nサンプルテキスト:\")\n",
                "for i, text in enumerate(texts[:3]):\n",
                "    print(f\"{i+1}. {text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. モデルのロード"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] モデル '{MODEL_NAME}' をロードしています...\")\n",
                "print(\"注意: 初回実行時はモデルのダウンロードが始まります（数分〜数十分かかる場合があります）\")\n",
                "\n",
                "model = SentenceTransformer(MODEL_NAME)\n",
                "\n",
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] モデルのロード完了\")\n",
                "print(f\"ベクトル次元数: {model.get_sentence_embedding_dimension()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. ベクトル化の実行"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] ベクトル化を開始します...\")\n",
                "print(f\"総テキスト数: {len(texts)}\")\n",
                "print(f\"バッチサイズ: {BATCH_SIZE}\")\n",
                "\n",
                "# ベクトル列名を生成\n",
                "vector_column = f\"vector_{MODEL_NAME.replace('/', '_').replace('.', '_').replace(':', '_')}\"\n",
                "print(f\"ベクトル列名: {vector_column}\")\n",
                "\n",
                "# バッチ処理でベクトル化\n",
                "all_vectors = []\n",
                "num_batches = (len(texts) + BATCH_SIZE - 1) // BATCH_SIZE\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "with tqdm(total=len(texts), desc=\"ベクトル化中\") as pbar:\n",
                "    for i in range(0, len(texts), BATCH_SIZE):\n",
                "        batch_texts = texts[i:i+BATCH_SIZE]\n",
                "        batch_vectors = model.encode(batch_texts, convert_to_numpy=True, show_progress_bar=False)\n",
                "        all_vectors.extend(batch_vectors)\n",
                "        pbar.update(len(batch_texts))\n",
                "\n",
                "end_time = time.time()\n",
                "duration = end_time - start_time\n",
                "\n",
                "print(f\"\\n[{time.strftime('%Y-%m-%d %H:%M:%S')}] ベクトル化完了\")\n",
                "print(f\"処理時間: {duration:.2f}秒\")\n",
                "print(f\"1件あたり: {duration/len(texts):.3f}秒\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. ベクトルをDataFrameに追加"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] ベクトルをDataFrameに追加しています...\")\n",
                "\n",
                "# ベクトルをJSON文字列に変換してDataFrameに追加\n",
                "df[vector_column] = [json.dumps(vec.tolist()) for vec in all_vectors]\n",
                "\n",
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 追加完了\")\n",
                "print(f\"\\nDataFrameの形状: {df.shape}\")\n",
                "print(f\"カラム数: {len(df.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. 結果の保存とダウンロード"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output_filename = \"ap_siken_all_items_vectors.csv\"\n",
                "\n",
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CSVファイルを保存しています...\")\n",
                "df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
                "print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] 保存完了: {output_filename}\")\n",
                "\n",
                "# ファイルサイズを表示\n",
                "file_size_mb = os.path.getsize(output_filename) / (1024 * 1024)\n",
                "print(f\"ファイルサイズ: {file_size_mb:.2f} MB\")\n",
                "\n",
                "# Google Colabの場合、ファイルをダウンロード\n",
                "print(\"\\nファイルをダウンロードしています...\")\n",
                "files.download(output_filename)\n",
                "print(\"ダウンロード完了！\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. 結果の確認（オプション）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ベクトルの次元数を確認\n",
                "sample_vector = json.loads(df[vector_column].iloc[0])\n",
                "print(f\"ベクトルの次元数: {len(sample_vector)}\")\n",
                "print(f\"\\nサンプルベクトル（最初の10次元）:\")\n",
                "print(sample_vector[:10])\n",
                "\n",
                "# データの統計情報\n",
                "print(f\"\\n=== 処理結果サマリー ===\")\n",
                "print(f\"総問題数: {len(df)}\")\n",
                "print(f\"使用モデル: {MODEL_NAME}\")\n",
                "print(f\"ベクトル次元数: {len(sample_vector)}\")\n",
                "print(f\"処理時間: {duration:.2f}秒\")\n",
                "print(f\"出力ファイル: {output_filename}\")\n",
                "print(f\"ファイルサイズ: {file_size_mb:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 完了！\n",
                "\n",
                "ベクトル化が完了しました。\n",
                "\n",
                "### 次のステップ\n",
                "\n",
                "1. ダウンロードした `ap_siken_all_items_vectors.csv` を `02_vectorize/output/` フォルダに配置\n",
                "2. `03_html_output/main.py` を実行して類似度を計算\n",
                "3. `index.html` をブラウザで開いて結果を確認"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
